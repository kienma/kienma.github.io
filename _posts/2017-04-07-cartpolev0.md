---
layout: post
title: Solving CartPole-v0 by Neuroevolution
---
### Introduction 
The [OpenAI Gym](https://gym.openai.com/docs) is a platform for developing and testing reinforcement 
learning algorithms. The Gym has many reinforcement learning tasks and uses an agent?action environment for 
reinforcement learning. Among these is the problem of balancing a pole on a cart, and one  
variation of the problem is [CartPole-v0](https://gym.openai.com/envs/CartPole-v0). 

The problem is,
> A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.

### Environment 
The environment can observe  **Cart Position**, **Cart Velocity**, **Pole Angle**, and **Pole Velocity at Tip**. 

There are two actions, which are discrete: 0 and 1. In the problem, the actions are push the cart to the left or right. 

Each episode starts at randomly generated values of each observation value. 

### Approaching the Problem
The problem is considered solved when the average score of 195.0 for 100 consecutive episodes. Thus, learning 
can be interpreted as an optimization task: maximize score. 

Since the actions are a discrete 0 and 1, a perceptron is appropriate for the problem. 
A [perceptron](https://en.wikipedia.org/wiki/Perceptron) is a simple artificial neuron that classifies a situation as `0` 
or `1`. In this problem, it is the following:

![alt text] (https://github.com/kienma/kienma.github.io/blob/master/images/neuralnet-cartpole-v0.png "Perceptron")

The perceptron uses observations for inputs and begins with randomly generated weights. Observations and 
weights are stored as vectors, *Z* and *wgt*, respectively, and the dot product of these vectors is the sum, 
`transfer`. 

The sum is then compared to the activation function `X` and makes a decision `action` to `0` or `1`. 
Effectively, the program decides whether to push the cart to the left or right based on varying values of the 
individual observations. However, the program has no idea what the appropriate weights are and needs to select
the appropriate weights so that the score is maximized. 

### Maximizing Score by Neuroevolution

I approached the problem by implementing a [genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm). 
A genetic algorithm is an evolutionary algorithm that utilizes genetic principles, like mutation and crossing, 
to produce a population of candidate solutions that approach an optimal solution. 

My algorithm begins with a population with `R` members, each having randomly generated weights, 
and I used `R=16` so that the population was neither too small nor large. Because of the randomly generated 
weighs, not all individuals are created equally, so each will have a particular score after one round. These scores 
are stored, and each individual now has a certain evolutionary fitness?its score in this round of evolution. 

The more fit individuals in the population are then selected; mutations are applied to their genomes; 
and these mutants are crossed to produce 16 new individuals, which are the new generation of individuals. This
generation is then evolved into another population for however many generations specified. 

#### Mutation 
From a molecular genetic perspective, each individual is composed of a genome. Each genome is composed of the four weights and changing an individual weight is mutation. 

Mutations are random, and to simulate random mutation, I used randomly generated numbers. The mutation was 
addition of a constant to a particular weight. Parallel to insertion and deletion, the constant added was either 
positive or negative. Most weights were not changed because I set the parameter ```mutation_rate = 20``` 
percent.

Here's [my sample mutation code](https://github.com/kienma/open-ai/blob/master/cartpole-v0/mutation_test2.py).

#### Crossing  
In my crossing step, I create random pairs of individuals among the top 50 percent-scoring individuals. 
From these pairs, which correspond to parents, a child is created. 

The child then randomly inherits weight *i* from either parent  1 or parent 2. The resulting child is a combination 
of the parents' features (weights) and is added to the next generation, which is in term used for the next level of evolution. 

Here's [my sample mating code](https://github.com/kienma/open-ai/blob/master/cartpole-v0/mating_test2.py). 

#### Results 
To measure how fitness evolved over time, I examined the mean score for the each generation. 

I used to following parameters:
```
X=1.8 # activation weight 
gens = 150 # 150 generations 
R=16 # 16 individuals per generation 
mutation_rate = 20 # mutation rate of 20 percent 
```

Plotting it in R: 
![alt text](https://github.com/kienma/kienma.github.io/blob/master/images/neuroevolution-cartpole-v0.png "Scores")

Initially the scores are low, but as a particularly beneficial allele is introduced into the population, the scores 
tend to increase a lot. It reminds me of [punctuated equilibrium](https://en.wikipedia.org/wiki/Punctuated_equilibrium). 

Eventually, the population arrives at a stable solution, evident by the mean score of 200 for several generations.
As alleles that are harmful to score are introduced to the population through random mutation, the mean score
occasionally decreases. 

The full code is available on my Github [here](https://github.com/kienma/open-ai/blob/master/cartpole-v0/evolution-v1-final.py). 
Since most of these parameters are easily changed, analysis of how each parameter affects the stability of the 
solutions and speed of convergence to a solution is doable. 

### Summary
CartPole-v0 is a reinforcement learning task, with the goal of maximizing score. The environment can observe
four values and take two discrete actions. 

A perceptron can decide discrete actions, making a decision based on weights and inputs. A population of 
perceptrons that decide on a CartPole-v0 action with randomly generated weights can evolve
 by selection, mutation of weights, and crossing weights. 

This evolution process can be applied to the evolved generation to continually evolve 
the population toward the maximum score. Within 100 generations, the population of candidate solutions 
evolved to that achieved an average score of 200. 

Thanks for reading!
